{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리\n",
    "\n",
    "- 결손값 - NaN, Null 변환 > 평균값 또는 드롭, 중요도 고려\n",
    "- 사이킷런 머신러닝 알고리즘은 문자열 값 입력값으로 허용 안함\n",
    "    - 모든 문자열 값은 인코딩돼서 숫자 형식으로 변환해야 함\n",
    "    - 문자열 피처 = 카테고리형, 텍스트형 피처 의미 \n",
    "        - 카테고리형 피처 = 코드 값으로 표현\n",
    "        - 텍스트형 피처 = 피처 벡터화, 삭제\n",
    "\n",
    "\n",
    "## 데이터 인코딩\n",
    "\n",
    "- 레이블 인코딩, 원핫 인코딩\n",
    "\n",
    "- 레이블 인코딩(Label encoding)\n",
    "    - 카테고리 피처를 코드형 숫자 값으로 변환하는 것\n",
    "\n",
    "\n",
    "### 레이블 인코딩\n",
    "\n",
    "- LabelEncoder 클래스로 구현 \n",
    "    - LabelEncoder 를 객체로 생성한 후 fit() 과 transform() 호출해 레이블 인코딩 수행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩 변환값:  [0 1 4 5 3 3 2 2]\n",
      "인코딩 클래스:  ['TV' '냉장고' '믹서' '선풍기' '전자레인지' '컴퓨터']\n",
      "디코딩 원본값:  ['전자레인지' '컴퓨터' '믹서' 'TV' '냉장고' '냉장고' '선풍기' '선풍기']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder \n",
    "\n",
    "items = ['TV','냉장고','전자레인지','컴퓨터','선풍기','선풍기','믹서','믹서']\n",
    "\n",
    "# LabelEncoder 를 객체로 생성한 후, fit() 과 transform() 으로 레이블 인코딩 수행\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items) \n",
    "labels = encoder.transform(items) \n",
    "\n",
    "print('인코딩 변환값: ', labels) \n",
    "\n",
    "# 문자열 값이 어떤 숫자 값으로 인코딩 됐는지 직관적으로 알고 싶으면 LabelEncoder 객체의 classes_ 속성값으로 확인\n",
    "print('인코딩 클래스: ', encoder.classes_)\n",
    "\n",
    "# inverse_transform() 인코딩 > 다시 디코딩\n",
    "print('디코딩 원본값: ', encoder.inverse_transform([4, 5, 2, 0, 1, 1, 3, 3,]))\n",
    "\n",
    "\n",
    "# 레이블 인코딩은 숫자 값의 크고작은 특성으로 예측 성능이 떨어질 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 원 핫 인코딩(one-hot Encoding) \n",
    "\n",
    "- 피처 값의 유형에 따라 새로운 피처를 추가해 고유 값에 해당하는 칼럼에만 1을 표시하고 나머지 컬럼에 0을 표시\n",
    "\n",
    "- 사이킷런 OneHotEncoder 클래스.\n",
    "   - 주의: 입력값으로 2차원 데이터 필요\n",
    "   - 변환값이 희소행렬(Sparse Matrix) 형태므로 다시 toarray() 메서드 이용해 밀집행렬(Dense Matrix) 변환."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원-핫 인코딩 데이터\n",
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n",
      "원-핫 인코딩 데이터 차원\n",
      "(8, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "items=['TV','냉장고','전자레인지','컴퓨터','선풍기','선풍기','믹서','믹서']\n",
    "\n",
    "# 2차원 ndarray로 변환합니다. \n",
    "items = np.array(items).reshape(-1, 1)\n",
    "\n",
    "# 원-핫 인코딩을 적용합니다. \n",
    "oh_encoder = OneHotEncoder()\n",
    "oh_encoder.fit(items)\n",
    "oh_labels = oh_encoder.transform(items)\n",
    "\n",
    "# OneHotEncoder로 변환한 결과는 희소행렬이므로 toarray()를 이용해 밀집 행렬로 변환. \n",
    "print('원-핫 인코딩 데이터')\n",
    "print(oh_labels.toarray())\n",
    "print('원-핫 인코딩 데이터 차원')\n",
    "print(oh_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>items_TV</th>\n",
       "      <th>items_냉장고</th>\n",
       "      <th>items_믹서</th>\n",
       "      <th>items_선풍기</th>\n",
       "      <th>items_전자레인지</th>\n",
       "      <th>items_컴퓨터</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   items_TV  items_냉장고  items_믹서  items_선풍기  items_전자레인지  items_컴퓨터\n",
       "0         1          0         0          0            0          0\n",
       "1         0          1         0          0            0          0\n",
       "2         0          0         0          0            1          0\n",
       "3         0          0         0          0            0          1\n",
       "4         0          0         0          1            0          0\n",
       "5         0          0         0          1            0          0\n",
       "6         0          0         1          0            0          0\n",
       "7         0          0         1          0            0          0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 판다스 원-핫 인코딩 지원 API get_dummies() \n",
    "# 문자열 카테고리 값을 숫자 형으로 변환할 필요 없이 바로 변환 가능\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'items':['TV','냉장고','전자레인지','컴퓨터','선풍기','선풍기','믹서','믹서']})\n",
    "pd.get_dummies(df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 피처 스케일링과 정규화\n",
    "\n",
    "- 피처스케일링(feature scaling): 서로 다른 변수의 값 범위를 일정한 수준으로 맞추는 작업\n",
    "\n",
    "    - 표준화(Standardization), 정규화(Normalization) \n",
    "        - 표준화: 데이터 피처 각각 평균 0, 분산 1인 가우시안 정규 분포 가진 값으로 변환\n",
    "            - 표준화 변환 피처 x 새로운 i 번째 데이터 x_new 면\n",
    "            - 원래 값에서 피처 x 평균을 뺀 값을 피처 x 표준편차로 나눈 값\n",
    "\n",
    "    - 정규화: 서로 다른 피처 크기를 통일하기 위해 크기를 변환\n",
    "        - 최소 0 ~ 최대 1 값으로 변환\n",
    "        - 개별 데이터 크기를 모두 똑같은 단위로 변경\n",
    "        - 새로운 데이터 x_new 는 원래 값에서 피처 x 의 최솟값을 뺀 값을 피처 x의 최댓값과 최솟값 차이로 나눈 값\n",
    "        - 사이킷런 Normalizer 모듈과 일반적인 정규화는 약간 차이\n",
    "            - 일반 표준화,정규화 = 피처 스케일링\n",
    "            - 선형대수 개념 정규화 = 벡터 정규화\n",
    "\n",
    "- 사이킷런 피처 스케일링 클래스: StandardScaler , MinMaxScaler            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### StandardScaler \n",
    "\n",
    "- 표준화 지원 클래스\n",
    "- 개별 피처를 평균 0, 분산 1 값으로 변환\n",
    "- 가우시안 정규분포\n",
    "- 서포트 벡터 머신(Support Vector Machine), 선형 회귀(Linear Regressor), 로지스틱 회귀(Logistic Regression) \n",
    "    - 데이터가 가우시안 정규분포 가정하고 구현해서 사전에 표준화 적용은 예측 성능 향상에 중요한 요소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature 들의 평균 값\n",
      "sepal length (cm)    5.843333\n",
      "sepal width (cm)     3.057333\n",
      "petal length (cm)    3.758000\n",
      "petal width (cm)     1.199333\n",
      "dtype: float64\n",
      "\n",
      "feature 들의 분산 값\n",
      "sepal length (cm)    0.685694\n",
      "sepal width (cm)     0.189979\n",
      "petal length (cm)    3.116278\n",
      "petal width (cm)     0.581006\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "# 붓꽃 데이터 셋을 로딩하고 DataFrame으로 변환합니다. \n",
    "iris = load_iris()\n",
    "iris_data = iris.data\n",
    "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
    "\n",
    "# 데이터 세트 확인\n",
    "print('feature 들의 평균 값')\n",
    "print(iris_df.mean())\n",
    "print('\\nfeature 들의 분산 값')\n",
    "print(iris_df.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature 들의 평균 값\n",
      "sepal length (cm)   -1.690315e-15\n",
      "sepal width (cm)    -1.842970e-15\n",
      "petal length (cm)   -1.698641e-15\n",
      "petal width (cm)    -1.409243e-15\n",
      "dtype: float64\n",
      "\n",
      "feature 들의 분산 값\n",
      "sepal length (cm)    1.006711\n",
      "sepal width (cm)     1.006711\n",
      "petal length (cm)    1.006711\n",
      "petal width (cm)     1.006711\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# StandardScaler 이용해 각 피처 한 번에 표준화하기\n",
    "# StandardScaler 객체 생성 - fit()과 transform() 메서드에 변환 대상 피처 데이터 세트 입력하고 호출하면 변환\n",
    "# transform() 호출할 때 스케일 변환된 데이터 세트가 넘파이의 ndarray 이므로 DataFarme 으로 변환해 평균값과 분산 값을 다시 확인\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# StandardScaler객체 생성\n",
    "scaler = StandardScaler()\n",
    "# StandardScaler 로 데이터 셋 변환. fit( ) 과 transform( ) 호출.  \n",
    "scaler.fit(iris_df)\n",
    "iris_scaled = scaler.transform(iris_df)\n",
    "\n",
    "#transform( )시 scale 변환된 데이터 셋이 numpy ndarry로 반환되어 이를 DataFrame으로 변환\n",
    "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n",
    "print('feature 들의 평균 값')\n",
    "print(iris_df_scaled.mean())\n",
    "print('\\nfeature 들의 분산 값')\n",
    "print(iris_df_scaled.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MinMaxScler\n",
    "\n",
    "- 데이터값을 0과 1사이 범위 값으로 변환(음수값 있으면 -1 ~ 1 값으로 변환) \n",
    "- 데이터 분포가 가우시안 분포가 아닌 경우 Min, Max scale 적용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature들의 최솟값\n",
      "sepal length (cm)    0.0\n",
      "sepal width (cm)     0.0\n",
      "petal length (cm)    0.0\n",
      "petal width (cm)     0.0\n",
      "dtype: float64\n",
      "\n",
      "feature들의 최댓값\n",
      "sepal length (cm)    1.0\n",
      "sepal width (cm)     1.0\n",
      "petal length (cm)    1.0\n",
      "petal width (cm)     1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# MinMaxScaler객체 생성\n",
    "scaler = MinMaxScaler()\n",
    "# MinMaxScaler 로 데이터 셋 변환. fit() 과 transform() 호출.  \n",
    "scaler.fit(iris_df)\n",
    "iris_scaled = scaler.transform(iris_df)\n",
    "\n",
    "# transform()시 scale 변환된 데이터 셋이 numpy ndarry로 반환되어 이를 DataFrame으로 변환\n",
    "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n",
    "print('feature들의 최솟값')\n",
    "print(iris_df_scaled.min())\n",
    "print('\\nfeature들의 최댓값')\n",
    "print(iris_df_scaled.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습 데이터와 테스트 데이터 스케일링 변환 시 유의점\n",
    "\n",
    "- 스케일링 변환 시 fit(), transform(), fit_transform() 메서드 이용\n",
    "- fit() : 데이터 변환을 위한 기준 정보 설정(예, 데이터 세트 최댓값/최솟값 설정 등) 적용\n",
    "- transform() : 설정된 정보를 이용해 데이터 변환\n",
    "- fit_transform() : fit() 과 transform() 을 한 번에 적용\n",
    "\n",
    "- 학습 데이터 세트와 테스트 데이터 세트에 fit() 과 transform() 적용 시 주의 필요\n",
    "    - Scaler 객체 이용 학습데이터 세트로 fit()과 transform() 적용하면 테스트 데이터 세트로는 다시 fit() 수행하지 않고 학습 데이터 세트로 fit()을 수행한 \n",
    "      결과를 이용해 transform() 변환을 적용해야 한다는 것 \n",
    "    - 즉, 학습 데이터로 fit()이 적용된 스케일링 기준 정보를 그대로 테스트 데이터에 적용해야 하며, 그렇지 않고 테스트 데이터로 다시 새로운 스케일링 기준 정보\n",
    "      를 만들게 되면 학습 데이터와 테스트 데이터의 스케일링 기준 정보가 달라져 올바른 예측 결과를 도출하지 못할 수도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터에 fit()을 적용할 때 문제 보기\n",
    "# np.arange() 이용 학습데이터를 0 ~ 10까지, 테스트 데이터를 0 ~ 5까지 가지는 ndarray 생성\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# 학습 데이터는 0 부터 10까지, 테스트 데이터는 0 부터 5까지 값을 가지는 데이터 세트로 생성\n",
    "# Scaler클래스의 fit(), transform()은 2차원 이상 데이터만 가능하므로 reshape(-1, 1)로 차원 변경\n",
    "train_array = np.arange(0, 11).reshape(-1, 1)\n",
    "test_array =  np.arange(0, 6).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 train_array 데이터: [ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "Scale된 train_array 데이터: [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n"
     ]
    }
   ],
   "source": [
    "# MinMaxScaler 객체에 별도의 feature_range 파라미터 값을 지정하지 않으면 0~1 값으로 변환\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# fit()하게 되면 train_array 데이터의 최솟값이 0, 최댓값이 10으로 설정.\n",
    "scaler.fit(train_array)\n",
    "\n",
    "# 1/10 scale로 train_array 데이터 변환함. 원본 10-> 1로 변환됨.\n",
    "train_scaled = scaler.transform(train_array)\n",
    "\n",
    "print('원본 train_array 데이터:', np.round(train_array.reshape(-1), 2))\n",
    "print('Scale된 train_array 데이터:', np.round(train_scaled.reshape(-1), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 test_array 데이터: [0 1 2 3 4 5]\n",
      "Scale된 test_array 데이터: [0.  0.2 0.4 0.6 0.8 1. ]\n"
     ]
    }
   ],
   "source": [
    "# MinMaxScaler에 test_array를 fit()하게 되면 원본 데이터의 최솟값이 0, 최댓값이 5로 설정됨\n",
    "scaler.fit(test_array)\n",
    "\n",
    "# 1/5 scale로 test_array 데이터 변환함. 원본 5->1로 변환.\n",
    "test_scaled = scaler.transform(test_array)\n",
    "\n",
    "# test_array의 scale 변환 출력.\n",
    "print('원본 test_array 데이터:', np.round(test_array.reshape(-1), 2))\n",
    "print('Scale된 test_array 데이터:', np.round(test_scaled.reshape(-1), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 train_array 데이터: [ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "Scale된 train_array 데이터: [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n",
      "\n",
      "원본 test_array 데이터: [0 1 2 3 4 5]\n",
      "Scale된 test_array 데이터: [0.  0.1 0.2 0.3 0.4 0.5]\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_array)\n",
    "train_scaled = scaler.transform(train_array)\n",
    "print('원본 train_array 데이터:', np.round(train_array.reshape(-1), 2))\n",
    "print('Scale된 train_array 데이터:', np.round(train_scaled.reshape(-1), 2))\n",
    "\n",
    "# test_array에 Scale 변환을 할 때는 반드시 fit()을 호출하지 않고 transform() 만으로 변환해야 함. \n",
    "test_scaled = scaler.transform(test_array)\n",
    "print('\\n원본 test_array 데이터:', np.round(test_array.reshape(-1), 2))\n",
    "print('Scale된 test_array 데이터:', np.round(test_scaled.reshape(-1), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit_transform() 적용은 학습데이터는 상관없지만 테스트데이터 에서는 절대 사용해선 안된다.\n",
    "\n",
    "따라서, 학습과 테스트데이터 세트로 분리하기 전에 전체 데이터 세트에 스케일링 적용한 뒤 학습과 테스트 데이터 세트로 분리하는 것이 바람직.\n",
    "\n",
    "* 유의점 정리\n",
    "1. 가능하면 전체 데이터의 스케일링 변환을 적용한 뒤 학습과 테스트 데이터 분리\n",
    "2. 1이 여의치 않다면 테스트 데이터 변환 시에는 fit()이나 fit_transform() 을 적용하지 않고 학습 데이터로 이미 fit() 된 Scaler 객체를 이용 transform() 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ca71aff40853dd846130b67975d07637ec6294bee047a07657cfc9075e3162be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
